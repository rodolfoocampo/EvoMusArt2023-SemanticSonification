This repository provides supporting documentation for the paper: "Using GPT-3 to achieve semantically relevant
data sonificiation for an art installation", submitted to the EvoMusArt conference in 2023. 

# Code

The sonificiation.py contains code used in the pipeline that turns data into natural language descriptions using GPT-3, which is then matched to sound labels in a sound library, which are then used to build a generative soundscape in real time. 

The diagram below describes the pipeline: 

The sonification file is provided to illustrate the approach described in the paper with code, however, in order to run it, one needs a connection to the MeMu propietary music engine and its tagged sound library, which is not provided. Therefore, this code is provided for illustration purposes rather than for it to be run.  

# Sound examples

It is possible to hear examples of how data was translated into natural language descriptions and then hear the sounds these were matched to in the following link: https://evomusart-semantic-sonificiation.glitch.me/

# Live Demo

A live demo can be seen in the folloing link: https://www.systemofasound.art/

![SystemofaSound](https://user-images.githubusercontent.com/20214121/214630338-086ef5ee-aec6-4285-bcf5-2bcab57d1afe.png)


https://user-images.githubusercontent.com/20214121/214635598-79f0d1c2-2f38-4992-bfac-a2db7aa058be.mov

